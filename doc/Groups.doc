
//_______________________________________________________________________________
//                                                                         pyBDSM

/*!
  \defgroup pybdsm pyBDSM : Python version of the BDSM software

  \verbatim
  lofarsoft
  |-- data
  |-- doc
  |-- release
  |-- build
  |-- devel_common
  |-- external
  `-- src
      |-- contrib
      |-- CR-Tools
      |-- DAL
      `-- pybdsm      <-- you are here
  \endverbatim
*/

//_______________________________________________________________________________
//                                                                        contrib

/*!
  \defgroup contrib Collection of user contributed code
	
  \verbatim
  lofarsoft
  |-- data
  |-- doc
  |-- release
  |-- build
  |-- devel_common
  |-- external
  `-- src
      |-- contrib        <-- you are here
      |   |-- shapelets
      |   |-- testing
      |   `-- utilities
      |-- CR-Tools
      |-- DAL
      `-- pybdsm
  \endverbatim
*/

//_______________________________________________________________________________
//                                                                       pipeline

/*!
  \defgroup pipeline Pipeline-Framework
	
  \verbatim
  lofarsoft
  |-- data
  |-- doc
  |-- release
  |-- build
  |-- devel_common
  |-- external
  `-- src
      |-- pipeline       <-- you are here
      |   |-- deploy
      |   |-- doc
      |   |-- examples
      |   |-- mac
      |   |-- pipeline
      |   `-- recipes
      |-- CR-Tools
      |-- DAL
      `-- pybdsm
  \endverbatim	
  
  The framework aims to make it possible to manage a variety of different
  processing steps in a flexible yet consistent way, while running them in
  parallel across the LOFAR offline cluster.

  <h4>Cluster Layout</h4>

  The pipeline framework makes the assumption that it will run on a cluster
  comprised of a "head node" and a number of "compute nodes". The pipeline
  control logic runs on the head node, and may perform less compute-intensive
  jobs here. When required, jobs are dispatched over the network to the compute
  nodes: the head node may then wait and receive the results before continuing.
  Job definition and parameters may be pushed to the compute nodes directly from
  the head using <a href="http://ipython.scipy.org">IPython</a>; however, for
  bandwidth and latency reasons, large data files should be written to and read
  from shared NFS mounts.

  <h4>Recipes</h4>

  A \b recipe is a unit of the pipeline. It consists of a a task with a given set
  of inputs and outputs. A given recipe may contain calls to subsidiary recipes,
  for which it will provide the inputs and use the outputs in its own
  processing. Note that the whole pipeline control structure is itself a recipe:
  it takes a given set of inputs (visibility data) and produces some outputs
  (images and associated metadata) by running through a series of defined steps.
  In fact, each of those steps is itself a recipe -- one for flagging, one for
  calibration, and so on.

  <h4>Control</h4>

  The \b control recipe is a specialist type of a normal recipe. The fundamentals
  are the same; however, it contains some additional "housekeeping" logic which
  may be useful for starting a pipeline. For instance, the control recipe can
  configure a logging system for the pipeline, and may be used to interface with
  LOFAR's MAC/SAS control system.

*/

//_______________________________________________________________________________
//                                                                   Pulsar-Tools

/*!
  \defgroup pulsar Pulsar-Tools : Collection of tools for pulsar data reduction
	
  \verbatim
  lofarsoft
  |-- data
  |-- doc
  |-- release
  |-- build
  |-- devel_common
  |-- external
  `-- src
      |-- contrib
      |-- CR-Tools
      |-- DAL
      |-- Pulsar         <-- you are here
      `-- pybdsm
  \endverbatim

  \section pulsar_presto Basic installation steps for Presto

  <ol>
    <li>Install FFTW3.X  You need to compile FFTW for _single_ precision (see
    the config flags I recommend below). <br>
    For all architectures I recommend the following configuration:
    \verbatim
    ./configure --enable-shared --enable-single
    \endverbatim
    Use the <tt>--prefix=SOME_PATH</tt> option to install the library and
    its related files to SOME_PATH.  (If you have admin access to your machine,
    <tt>--prefix=/usr/local</tt> is the default for FFTW and is a safe bet). <br>
    If you have a modern version of GCC installed (v3.2 or better) 
    and a modern CPU (Intel Pentium IV, or newer; AMD Opteron 
    or better, G5), you can get _drastically_ better performance by
    adding the following options:
    <ul>
      <li>For Intel PIVs or later, EM64Ts, or AMD64s:
      \verbatim
      --enable-sse
      \endverbatim
      <li>For Mac G5s:
      \verbatim
      --enable-altivec
      \endverbatim
    </ul>

    <li>Install <a href="http://www.astro.caltech.edu/~tjp/pgplot">PGPLOT</a>.
    You need the X-windows and postscript drivers at a minimum.

    <li>Install <a href="http://pulsar.princeton.edu/tempo/index.html">TEMPO</a>.
    Make sure to set the TEMPO environment variable.

    <li>Install <a href="http://library.gnome.org/devel/glib">GLIB</a> (v2.X). 
    On Linux machines this is almost certainly already on your system (check in
    <tt>/usr/lib</tt> and <tt>/usr/include/glib*</tt>). Although you may need to
    install a glib development package in order to have the required include 
    files...

    <li>Install <a href="http://heasarc.gsfc.nasa.gov/fitsio">CFITSIO</a>.
    This is a very easy install and is now needed since PSRFITS
    is now being written by several pulsar instruments (Nice!
    a pulsar data standard that external tools can actually
    view!  How about that!)

    <li>Define the PRESTO environment variable to the top level
    directory of the PRESTO distribution (i.e. this directory).

    <li>cd to <tt>$PRESTO/src</tt>.  Check and modify the Makefile for your
    machine of choice.  Insure that the library and include file
    directories are correct for FFTW, PGPLOT, GLIB, CFITSIO, 
    and TEMPO.

    <li>If you are using FFTW, do a 'make makewisdom'.  This gets
    FFTW acquainted with your system.  It is best if you are the
    only user on the machine when you run this, as it is very
    computation intensive and may take a while.

    <li>Just for safety's sake (and because SVN sometimes messes up
    file access times), do a "make prep".  That will make sure
    that make does not try to run Clig to re-generate all of the
    command line interface files.

    <li>Do a \e make.  This will make all of the executables.  If you
    want mpiprepsubband (for parallel de-dispersion on clusters) 
    you will need to do a 'make mpi' as well.

    <li>The required libraries and miscellaneous files will be
    located in $PRESTO/lib. The executable will be in <tt>$PRESTO/bin</tt>.
    You may copy or move the executables wherever you like, but 
    the library files should stay put.  (That's why you define the 
    PRESTO variable -- so the routines can find them).

    <li>If you want to save some disk space, do a 'make clean' in
    the 'src' directory.  This will leave the libraries and
    binaries in their respective directories but will get rid of
    all the extra stuff in the 'src' directory.

    <li>If you want to use all the python routines (which if you are
    doing anything but the most rudimentary analyses you will want 
    to), you need Python >= version 2.3, and the _new_ Numpy/SciPy.  
    You can get Numpy/Scipy here: <a href="http://www.scipy.org/download">http://www.scipy.org/download</a> <br>
    I recommend using the Subversion versions (and for PRESTO 
    as well).  In general, the following should work:
    \verbatim
    "cd $PRESTO/python ; make ; make fftfit"
    \endverbatim
    If it doesnt, you will probably need to edit the Makefile 
    or setup.py.

    <li>Go find pulsars!
  </ol>
*/

//_______________________________________________________________________________
//                                                                     Star-Tools

/*!
  \defgroup startools Star-Tools function collection

  \verbatim
  lofarsoft
  |-- data
  |-- doc
  |-- release
  |-- build
  |-- devel_common
  |-- external
  |   |-- casacore
  |   |-- hdf5
  |   `-- startools   <-- you are here
  `-- src
  \endverbatim
*/

//_______________________________________________________________________________
//                                                                   RM Synthesis

/*!
  \defgroup RM RM-Synthesis package

  \verbatim
  lofarsoft
  |-- data
  |-- doc
  |-- release
  |-- build
  |-- devel_common
  |-- external
  `-- src
      `-- RM          <-- you are here
  \endverbatim

  <h3>External packages</h3>

  - \ref external_packages_armadillo
  - \ref external_packages_itpp
*/

//_______________________________________________________________________________
//                                                                           LASA

/*!
  \defgroup LASA LOFAR Air-Shower Array (LASA)

  - \ref lasa_setup
  - \ref lasa_build
  - \ref lasa_update
  - \ref lasa_commit

  \section lasa_setup Setting up your working copy

  \b Note: This essentially is the  same procedure as already described in the
  \ref configure_build_install.

  <ol>
    <li>For the initial checkout of your working copy run:
    \verbatim
    svn co http://usg.lofar.org/svn/code/trunk lofarsoft
    \endverbatim
    Once the checkout is complete, you will find a new directory \b lofarsoft
    with the following sub-structure:
    \verbatim
    lofarsoft
    |-- data
    |-- doc
    |-- release
    |-- build
    |-- devel_common
    |-- external
    `-- src
        `-- LASA
            |-- analysis
	    `-- test
    \endverbatim
    The source code is in \b src/LASA, while the compile and installation is done
    from \b build.

    <li>Set up your environment: Add the location of the new executables to your
    PATH variable:
    \verbatim
    # csh, tcsh
    setenv LOFARSOFT <root directory of code tree>
    source $LOFARSOFT/devel_common/scripts/init.csh

    # sh, bash
    export LOFARSOFT=<root directory of code tree>
    . $LOFARSOFT/devel_common/scripts/init.sh
    \endverbatim
    If you want this information to be persistent, you should add the setting to
    the configuration file of your shell; for bash users this is done in either
    $HOME/.profile or $HOME/.bashrc â€“ users of tcsh or csh need to add the 
    appropriate statement to $HOME/.cshrc. 
  </ol>

  \section lasa_build Compile the software

  <ol>
    <li>Change into the \b build directory and run the \e bootstrap script:
    \verbatim
    cd build
    ./bootstrap
    \endverbatim
    The major job of the script is to check whether or not a recent version of
    CMake is available on your system; if this is not the case, CMake will be
    build from the provided sources and installed into \b release/bin (which 
    means that of course you should have that directory in your PATH).

    <li>Build the components  of the LASA software package:
    \verbatim
    make lasa
    \endverbatim

    <li>Once the initial build of the package is done -- which also includes
    checking the presence (and if required  build) of external packages, the
    fastest route to build the LASA software while developing and writing new
    code, is by running \e make within the \b build/lasa directory:
    \verbatim
    cd build/lasa
    make
    \endverbatim
  </ol>

  \section lasa_update Update your working copy

  <ol>
    <li>The savest way to update your existing working copy is to run
    \verbatim
    cd build
    make update
    \endverbatim
    from the \e build directory; this will ensure, that not only you will be
    picking up changes in the source code, but also adjustments to the build
    environment.
  </ol>

  \section lasa_commit Committing changes

  Once  you have made changes to the source code, checking them back into the
  repository works as follows:

  <ol>
    <li>Change into the directory holding the source code:
    \verbatim
    cd src/LASA
    \endverbatim

    <li>Commit the changes by typing
    \verbatim
    svn commit
    \endverbatim
    or
    \verbatim
    svn commit -m "Your short comment about the changes made."
    \endverbatim
    While the first variant will open an editor window for you to type in a
    short commit report, the second variant allows you to directly provide such
    a short statement -- describing what changes were done to the code -- from
    the command line.
  </ol>
*/

